# -*- coding: utf-8 -*-
"""Copy of GroupVII.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UUozdrrOyyk2VWEyC4QMetYVoeHrY4gh

# PROFILING GREENHOUSE GAS EMISSIONS IN RELATION TO POLLUTION LEVELS IN EUROPEAN COUNTRIES

# Importing libraries
"""

# First we import the python software libraries that we will use here
# Import Pandas library
import pandas as pd

# Import numpy library
import numpy as np

# To load the first dataset and preview them from the given links
# You can either download file in link or use the url to access the file
# historical_emissions dataset []
# Nuclear_energy []


# To load historical emissions dataset, download the file on my computer then uploaded 
# them on the colab and read them as excel and later converted them to csv files for ease of use

historical_emissions = pd.read_csv('historical_emissions.csv')
historical_emissions

# Getting to know more about the dataset by accessing its information
#
historical_emissions.info()

"""# Checking for missing values"""

# Creating a function to check
def missing_values(data):

  # identify the missing values from the historical emmisions dataset
  #
  miss = data.isnull().sum().sort_values(ascending = False)
  # the percentage of missing values
  percentage = (data.isnull().sum() / len(data)).sort_values(ascending = False)
  #storing  total missing values in percentage in dataframe
  #
  missing_data = pd.DataFrame({'Total' : miss, 'Percentage' : percentage})
  #if the percentage is 0, indicates no missing values hence removed
  #
  missing_data.drop(missing_data[missing_data['Percentage'] == 0].index, inplace = True)

  return missing_data

missing_values(historical_emissions)

# Creating a function to drop unnecessary columns
#
def drop_columns(data, cols):
  #drop columns not required
  data.drop(cols, axis = 1, inplace = True)

  return data

#columns to be dropped
columns = ['Gas', 'Data source',  '1990', '1991','1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2015','2016', '2017', '2018']
historical_df = drop_columns(historical_emissions, columns)

"""Conclusion

We dropped the gas column as it indicates the type of gas which was 
already defined earlier

We dropped the column data source as it will not be used for analysis
We dropped the years columns from 1990-2003 because we are only analysing data from 2004-2014

We dropped years 2015-2018 as they had many missing values
"""

# preview the altered table contents

historical_df.head()

# Checking for outliers
# check to see if any values appear True if so they are outliers
#
Q1 = historical_df.quantile(0.25)
Q3 = historical_df.quantile(0.75)

IQR = Q3 - Q1


(historical_df < (Q1 - 1.5 * IQR)) |(historical_df > (Q3 + 1.5 * IQR))

# If we were to keep our complete rows; meaning we drop any record with a missing value, then
#
historical_df = historical_df.dropna()

historical_df.shape

# Checking for completeness of data
# Explanation: checking if any columns have missing values
#
historical_df.isnull().any()

# Duplicates
# Data Cleaning Action: No action taken
# Explanation: There were no duplicate instances
#
historical_df.duplicated()

# To check for missing value in data

historical_df.isnull()

# This returns a boolean value for all cells that have NaN value

# In country column, drop European union 27 as it is an average of all european countries

historical_df = historical_df[historical_df.Country != "European Union (27)"]
historical_df

historical_df.reset_index(drop=True, inplace=True)
historical_df

# To get the number of row and columns in the dataset
historical_df.shape

historical_df = historical_df.sort_values(
     by="Country",
     ascending=True
 )

historical_df

historical_df.reset_index(drop=True, inplace=True)
historical_df.head()

"""Second dataset"""

# Load the second dataset
nuclear = pd.read_csv('Nuclear energy.csv')

nuclear = nuclear.iloc[3:]

nuclear = nuclear.drop('World Development Indicators', axis = 1)
nuclear.head()
nuclear = nuclear.drop(columns = ['Unnamed: 2', 'Unnamed: 3','Unnamed: 5','Unnamed: 6','Unnamed: 7', 'Unnamed: 8','Unnamed: 10','Unnamed: 11','Unnamed: 12', 'Unnamed: 13','Unnamed: 15','Unnamed: 16','Unnamed: 17', 'Unnamed: 18','Unnamed: 20','Unnamed: 21','Unnamed: 22', 'Unnamed: 23','Unnamed: 25','Unnamed: 26','Unnamed: 27', 'Unnamed: 28','Unnamed: 30','Unnamed: 31','Unnamed: 32', 'Unnamed: 33','Unnamed: 35','Unnamed: 36','Unnamed: 37', 'Unnamed: 38','Unnamed: 41','Unnamed: 42', 'Unnamed: 43','Unnamed: 45','Unnamed: 46','Unnamed: 47'], axis = 1)
nuclear.head()
nuclear = nuclear.drop(columns = ['Unnamed: 4','Unnamed: 9','Unnamed: 14','Unnamed: 19','Unnamed: 24'],axis = 1)
nuclear.head()
nuclear = nuclear.drop(columns = ['Unnamed: 29','Unnamed: 34','Unnamed: 39','Unnamed: 40','Unnamed: 44','Unnamed: 59','Unnamed: 60'], axis = 1)
nuclear.head()
nuclear = nuclear.drop(columns = ['Unnamed: 61','Unnamed: 62','Unnamed: 63','Unnamed: 64'], axis = 1)
nuclear.head()

# Change the header row from unnamed row to row index 0
#

header_row = 0
nuclear.columns = nuclear.iloc[header_row]
nuclear.head(10)

# Drop row 3 as it is irrelevant to our analysis

nuclear.drop([3],axis = 0, inplace = True)
nuclear.head()

# Rename columns for consistency with previous dataset

columns = ['Country', '2004', '2005', '2006','2007','2008','2009','2010','2011','2012','2013','2014']
nuclear.columns = columns
nuclear.head()

# Getting rows with european countries only

EU = ['Germany', 'France', 'Italy', 'Spain', 'Poland', 'Romania', 'Netherlands', 'Belgium', 'Czech Republic','Greece', 'Portugal', 'Sweden', 'Hungary', 'Austria', 'Bulgaria', 'Denmark', 'Finland', 'Slovakia', 'Ireland', 'Croatia', 'Lithuania', 'Slovenia', 'Latvia', 'Estonia', 'Luxembourg', 
'Malta']
euronuclear = nuclear[nuclear.Country.isin(EU)]
euronuclear

euronuclear.count()

# reset the index to have consistency

euronuclear.reset_index(drop=True, inplace=True)
euronuclear

# Sort the country names to alphabetical

euronuclear = euronuclear.sort_values(
     by="Country",
     ascending= True
 )
euronuclear

# Reset index for consistency
euronuclear.reset_index(drop=True, inplace=True)
euronuclear

# Merge the datasets

merged = historical_df.merge(euronuclear, how = 'left', on = 'Country' )
merged

"""# Analysis

1. To assess which European countries have high carbon emissions.
"""

#paris_data[(paris_data['kind'] == 'STATION') & (paris_data['status'] == 'ok')].groupby('public name')['public name'].count().sort_values(ascending= False).head(1);
#paris_data = Electric_data[Electric_data['city'] =='Paris'] 

#paris_data.head()historical_df[(historical_df['Sector'] == 'Total including LUCF')].groupby('2004')['2004'].count().sort_values(ascending= False).head(1);

total_data = historical_df[historical_df['Sector'] =='Total including LUCF'] 

total_data.head()

#total_data[(total_data['Sector'] == 'Total including LUCF')].groupby('Country')['Country'].count().sort_values(ascending= False).head(1);
column = total_data["2014"]
max_value = column.max()
print(max_value)

column = total_data["2013"]
max_value = column.max()
print(max_value)

total_data.max()

#total_data[(total_data['2004'] == '802.5')].groupby('Country')['Country'];
entry = total_data.groupby(['Country'])['2004'].max().sort_values(ascending= False).head(1)
entry

"""2. To investigate which year had the most carbon emissions."""



"""3. To find which sub sectors had the most greenhouse gas emissions."""

grouped = historical_df.groupby(['Sector'])['2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014'].sum()
grouped

"""4. To find which European countries have embraced nuclear power as an alternative source of energy."""

euronuclear

"""5. To compare pollution levels of European countries that have embraced nuclear energy and those that have not and the years they adopted nuclear energy.

"""

